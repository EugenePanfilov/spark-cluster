# OTUS. PySpark

Для подключения к proxy виртуальной машине
`ssh -i <your ssh private key> -L 8888:localhost:8888 <user>@<public ip vm>`

Для подключения к мастер-ноде
`ssh -L 8888:localhost:8888 ubuntu@<fqdn dataproc master node>`

Скопировать скрипт с локальной машины на мастер-ноду кластера:
`scp prepare_fraud_dataset.py dataproc-master:/home/ubuntu/`

Запуск скрипта обработки данных на спарк-кластере. Команда запускается на мастер-ноде кластера:
`spark-submit --master yarn prepare_fraud_dataset.py`

Скрипт берёт сырые CSV/TXT файлы с транзакциями из HDFS, объединяет их в один DataFrame в Spark, удаляет мусорные строки и задаёт понятные имена колонкам. Затем он приводит поля к нужным типам, парсит `tx_datetime` и отбрасывает записи, где дата не распарсилась. После этого данные сохраняются в HDFS в формате Parquet. Далее скрипт делает недельную агрегацию по количеству fraud-операций, строит столбчатый график и загружает изображение в HDFS.

